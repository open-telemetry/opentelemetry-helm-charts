# yaml-language-server: $schema=./values.schema.json
default:
  # List of environment variables applied to all components
  env:
    - name: OTEL_SERVICE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: "metadata.labels['app.kubernetes.io/component']"
    - name: OTEL_COLLECTOR_NAME
      value: otel-collector
    - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      value: cumulative
    - name: OTEL_RESOURCE_ATTRIBUTES
      value: "service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version={{ .Chart.AppVersion }}"
  # Allows overriding and additions to .Values.default.env
  envOverrides: []
  #  - name: OTEL_K8S_NODE_NAME
  #    value: "someConstantValue"
  image:
    repository: thouqueerahmedml/otel-demo
    # Overrides the image tag whose default is the chart appVersion.
    # The service's name will be applied to the end of this value.
    tag: latest
    pullPolicy: Always
    pullSecrets: []
  # Default # of replicas for all components
  replicas: 1
  # default revisionHistoryLimit for all components (number of old ReplicaSets to retain)
  revisionHistoryLimit: 10
  # Default schedulingRules for all components
  schedulingRules:
    nodeSelector: {}
    affinity: {}
    tolerations: []
  # Default securityContext for all components
  securityContext: {}

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

components:
  ## Demo Components are named objects (services) with several properties
  # demoService:
  ## Enable the component (service)
  #   enabled: true
  #   useDefault:
  ## Use default environment variables
  #     env: true
  ## Override Image repository and Tag. Tag will use appVersion as default.
  ## Component's name will be applied to end of this value.
  #   imageOverride: {}
  ## Optional service definitions to apply
  #   service:
  ## Service Type to use for this component. Default is ClusterIP.
  #     type: ClusterIP
  ## Service Port to use to expose this component. Default is nil
  #     port: 8080
  ## Service Node Port to use to expose this component on a NodePort service. Default is nil
  #     nodePort: 30080
  ## Service Annotations to add to this component
  #     annotations: {}
  ## Additional service ports to use to expose this component
  #   ports:
  #     - name: extraServicePort
  #       value: 8081
  ## Environment variables to add to the component's pod
  #   env:
  ## Environment variables that upsert (append + merge) into the `env` specification for this component.
  ## A variable named OTEL_RESOURCE_ATTRIBUTES_EXTRA will have its value appended to the OTEL_RESOURCE_ATTRIBUTES value.
  #   envOverrides:
  ## Pod Scheduling rules for nodeSelector, affinity, or tolerations.
  #   schedulingRules:
  #     nodeSelector: {}
  #     affinity: {}
  #     tolerations: []
  ## Pod Annotations to add to this component
  #   podAnnotations: {}
  ## Resources for this component
  #   resources: {}
  ## Container security context for setting user ID (UID), group ID (GID) and other security policies
  #   securityContext:
  ## Ingresses rules to add for the to the component
  # ingress:
  ## Enable the creation of Ingress rules. Default is false
  #   enabled: false
  ## Annotations to add to the ingress rule
  #   annotations: {}
  ## Which Ingress class (controller) to use. Default is unspecified.
  #   ingressClassName: nginx
  ## Hosts definitions for the Ingress rule
  #   hosts:
  #     - host: demo.example.com
  ## Each host can have multiple paths/routes
  #       paths:
  #         - path: /
  #           pathType: Prefix
  #           port: 8080
  ## Optional TLS specifications for the Ingress rule
  #   tls:
  #     - secretName: demo-tls
  #       hosts:
  #         - demo.example.com
  ## Additional ingresses - only created if ingress.enabled is true
  ## Useful for when differently annotated ingress services are required
  ## Each additional ingress needs key "name" set to something unique
  #   additionalIngresses: []
  #     - name: extra-demo-ingress
  #       ingressClassName: nginx
  #       annotations: {}
  #       hosts:
  #         - host: demo.example.com
  #           paths:
  #             - path: /
  #               pathType: Prefix
  #               port: 8080
  #       tls:
  #         - secretName: demo-tls
  #           hosts:
  #             - demo.example.com
  ## Command to use in the container spec, in case you don't want to go with the default command from the image.
  #   command: []
  ## Configuration to for this component; will create a Volume, and Mount backed by an optionally created ConfigMap.
  ## The name, mountPath are required, and one of existingConfigMap or data is required.
  ## If an existing ConfigMap is not provided, the contents under data will be used for the created ConfigMap.
  #   mountedConfigMaps: []
  #     - name: my-config
  #       mountPath: /etc/config
  #       subPath:
  #       existingConfigMap: my-configmap
  #       data:
  #         my-config.yaml: |
  #           key: value
  # # Kubernetes container health check options
  #   livenessProbe: {}
  # # Optional init container to run before the pod starts.
  #   initContainers:
  #     - name: <init-container-name>
  #       image: <init-container-image>
  #       command: [list of commands for the init container to run]
  # # Replicas for the component
  #  replicas: 1
  # # Number of old ReplicaSets to retain
  #  revisionHistoryLimit: 10
  # # Optional pod security context for setting user ID (UID), group ID (GID) and other security policies
  # # This will be applied at pod level, can be applied globally for all pods: .Values.default.podSecurityContext
  # # Or it can be applied to a specific component: .Values.components.<component-name>.podSecurityContext
  #    podSecurityContext:
  #      runAsGroup: 65534
  #      runAsNonRoot: true
  #      runAsUser: 65534

  accounting:
    enabled: true
    useDefault:
      env: true
    env:
      - name: KAFKA_ADDR
        value: kafka:9092
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318
      - name: DB_CONNECTION_STRING
        value: "Host=postgresql;Username=otelu;Password=otelp;Database=otel;Pooling=false;"
      - name: OTEL_DOTNET_AUTO_TRACES_ENTITYFRAMEWORKCORE_INSTRUMENTATION_ENABLED
        value: "false"
    resources:
      limits:
        memory: 512Mi
    initContainers:
      - name: wait-for-kafka
        image: busybox:latest
        command:
          [
            "sh",
            "-c",
            "until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;",
          ]
      - name: wait-for-postgres
        image: postgres:15
        command:
          [
            "sh",
            "-c",
            "until pg_isready -h postgresql -p 5432; do echo 'Waiting for PostgreSQL...'; sleep 2; done;",
          ]
      - name: wait-for-kafka-topic-orders
        image: confluentinc/cp-kafka:latest
        command:
          - "sh"
          - "-c"
          - |
            echo "Waiting for Kafka topic 'orders' to be available..."
            until kafka-topics --bootstrap-server kafka:9092 --list | grep -q "^orders$"; do
              echo "Topic 'orders' not found, waiting..."
              sleep 5
            done
            echo "Topic 'orders' is available!"
      - name: wait-for-postgresql
        image: busybox:latest
        command:
          [
            "sh",
            "-c",
            "until nc -z -v -w30 postgresql 5432; do echo waiting for postgresql; sleep 2; done;",
          ]

  ad:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: AD_PORT
        value: "8080"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318
      - name: OTEL_LOGS_EXPORTER
        value: otlp
    resources:
      limits:
        memory: 512Mi

  cart:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: CART_PORT
        value: "8080"
      - name: ASPNETCORE_URLS
        value: http://*:$(CART_PORT)
      - name: VALKEY_ADDR
        value: valkey-cart:6379
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 160Mi
    initContainers:
      - name: wait-for-valkey-cart
        image: busybox:latest
        command:
          [
            "sh",
            "-c",
            "until nc -z -v -w30 valkey-cart 6379; do echo waiting for valkey-cart; sleep 2; done;",
          ]

  checkout:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: CHECKOUT_PORT
        value: "8080"
      - name: CART_ADDR
        value: cart:8080
      - name: CURRENCY_ADDR
        value: currency:8080
      - name: EMAIL_ADDR
        value: http://email:8080
      - name: PAYMENT_ADDR
        value: payment:8080
      - name: PRODUCT_CATALOG_ADDR
        value: product-catalog:8080
      - name: SHIPPING_ADDR
        value: http://shipping:8080
      - name: KAFKA_ADDR
        value: kafka:9092
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 128Mi
    initContainers:
      - name: wait-for-kafka
        image: busybox:latest
        command:
          [
            "sh",
            "-c",
            "until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;",
          ]

  currency:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: CURRENCY_PORT
        value: "8080"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
      - name: VERSION
        value: "{{ .Chart.AppVersion }}"
    resources:
      limits:
        memory: 20Mi

  email:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: EMAIL_PORT
        value: "8080"
      - name: APP_ENV
        value: production
      - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
    resources:
      limits:
        memory: 512Mi

  fraud-detection:
    enabled: false
    useDefault:
      env: true
    env:
      - name: KAFKA_ADDR
        value: kafka:9092
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318
    resources:
      limits:
        memory: 300Mi
    initContainers:
      - name: wait-for-kafka
        image: busybox:latest
        command:
          [
            "sh",
            "-c",
            "until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;",
          ]
      - name: wait-for-kafka-topic-orders
        image: confluentinc/cp-kafka:latest
        command:
          - "sh"
          - "-c"
          - |
            echo "Waiting for Kafka topic 'orders' to be available..."
            until kafka-topics --bootstrap-server kafka:9092 --list | grep -q "^orders$"; do
              echo "Topic 'orders' not found, waiting..."
              sleep 5
            done
            echo "Topic 'orders' is available!"

  kafka-exporter:
    enabled: true
    imageOverride:
      repository: "danielqsj/kafka-exporter"
      tag: "latest"
    command:
      - "/bin/kafka_exporter"
      - "--kafka.server=kafka:9092"
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9308"
    service:
      port: 9308
    useDefault:
      env: false
    resources:
      limits:
        memory: 300Mi
    initContainers:
      - name: wait-for-kafka
        image: busybox:latest
        command:
          [
            "sh",
            "-c",
            "until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;",
          ]

  frontend:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: FRONTEND_PORT
        value: "8080"
      - name: FRONTEND_ADDR
        value: :8080
      - name: AD_ADDR
        value: ad:8080
      - name: CART_ADDR
        value: cart:8080
      - name: CHECKOUT_ADDR
        value: checkout:8080
      - name: CURRENCY_ADDR
        value: currency:8080
      - name: PRODUCT_CATALOG_ADDR
        value: product-catalog:8080
      - name: RECOMMENDATION_ADDR
        value: recommendation:8080
      - name: SHIPPING_ADDR
        value: http://shipping:8080
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_COLLECTOR_HOST
        value: $(OTEL_COLLECTOR_NAME)
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
      - name: WEB_OTEL_SERVICE_NAME
        value: frontend-web
      - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
        value: http://localhost:8080/otlp-http/v1/traces # This expects users to use `kubectl port-forward ...`
    resources:
      requests:
        memory: 512Mi
      limits:
        memory: 512Mi
    securityContext:
      runAsUser: 1001 # nextjs
      runAsGroup: 1001
      runAsNonRoot: true

  frontend-proxy:
    enabled: true
    useDefault:
      env: true
    service:
      type: LoadBalancer
      port: 8080
    env:
      - name: ENVOY_PORT
        value: "8080"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: FLAGD_UI_HOST
        value: flagd
      - name: FLAGD_UI_PORT
        value: "4000"
      - name: FRONTEND_HOST
        value: frontend
      - name: FRONTEND_PORT
        value: "8080"
      - name: GRAFANA_HOST
        value: grafana
      - name: GRAFANA_PORT
        value: "80"
      - name: IMAGE_PROVIDER_HOST
        value: image-provider
      - name: IMAGE_PROVIDER_PORT
        value: "8081"
      - name: JAEGER_HOST
        value: jaeger-query
      - name: JAEGER_PORT
        value: "80"
      - name: LOCUST_WEB_HOST
        value: load-generator
      - name: LOCUST_WEB_PORT
        value: "8089"
      - name: OTEL_COLLECTOR_HOST
        value: $(OTEL_COLLECTOR_NAME)
      - name: OTEL_COLLECTOR_PORT_GRPC
        value: "4317"
      - name: OTEL_COLLECTOR_PORT_HTTP
        value: "4318"
    resources:
      requests:
        memory: 128Mi
      limits:
        memory: 128Mi
    securityContext:
      runAsUser: 101 # envoy
      runAsGroup: 101
      runAsNonRoot: true

  image-provider:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8081
    env:
      - name: IMAGE_PROVIDER_PORT
        value: "8081"
      - name: OTEL_COLLECTOR_PORT_GRPC
        value: "4317"
      - name: OTEL_COLLECTOR_HOST
        value: $(OTEL_COLLECTOR_NAME)
    resources:
      limits:
        memory: 50Mi

  load-generator:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8089
    env:
      - name: LOCUST_WEB_HOST
        value: "0.0.0.0"
      - name: LOCUST_WEB_PORT
        value: "8089"
      - name: LOCUST_USERS
        value: "10"
      - name: LOCUST_SPAWN_RATE
        value: "1"
      - name: LOCUST_HOST
        value: http://frontend-proxy:8080
      - name: LOCUST_HEADLESS
        value: "false"
      - name: LOCUST_AUTOSTART
        value: "true"
      - name: LOCUST_BROWSER_TRAFFIC_ENABLED
        value: "true"
      - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
        value: python
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_OFREP_PORT
        value: "8016"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 1500Mi

  payment:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: PAYMENT_PORT
        value: "8080"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      requests:
        memory: 256Mi
      limits:
        memory: 256Mi
    securityContext:
      runAsUser: 1000 # node
      runAsGroup: 1000
      runAsNonRoot: true

  product-catalog:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: PRODUCT_CATALOG_PORT
        value: "8080"
      - name: PRODUCT_CATALOG_RELOAD_INTERVAL
        value: "10"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    mountedConfigMaps:
      - name: product-catalog-products
        mountPath: /usr/src/app/products
        existingConfigMap: product-catalog-products
    resources:
      requests:
        memory: 256Mi
      limits:
        memory: 256Mi

  quote:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: QUOTE_PORT
        value: "8080"
      - name: OTEL_PHP_AUTOLOAD_ENABLED
        value: "true"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4318
    resources:
      limits:
        memory: 40Mi
    securityContext:
      runAsUser: 33 # www-data
      runAsGroup: 33
      runAsNonRoot: true

  recommendation:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: RECOMMENDATION_PORT
        value: "8080"
      - name: PRODUCT_CATALOG_ADDR
        value: product-catalog:8080
      - name: OTEL_PYTHON_LOG_CORRELATION
        value: "true"
      - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
        value: python
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 200Mi
        cpu: 100m

  shipping:
    enabled: true
    useDefault:
      env: true
    service:
      port: 8080
    env:
      - name: SHIPPING_PORT
        value: "8080"
      - name: QUOTE_ADDR
        value: http://quote:8080
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://$(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 20Mi

  flagd:
    enabled: true
    imageOverride:
      repository: "ghcr.io/open-feature/flagd"
      tag: "v0.12.9"
    useDefault:
      env: true
    replicas: 1
    ports:
      - name: rpc
        value: 8013
      - name: ofrep
        value: 8016
    env:
      - name: FLAGD_METRICS_EXPORTER
        value: otel
      - name: FLAGD_OTEL_COLLECTOR_URI
        value: $(OTEL_COLLECTOR_NAME):4317
    resources:
      limits:
        memory: 75Mi
    command:
      - "/flagd-build"
      - "start"
      - "--port"
      - "8013"
      - "--ofrep-port"
      - "8016"
      - "--uri"
      - "file:./etc/flagd/demo.flagd.json"
    mountedEmptyDirs:
      - name: config-rw
        mountPath: /etc/flagd
    # flgad-ui as a sidecar container in the same pod so the flag json file can be shared
    sidecarContainers:
      - name: flagd-ui
        imageOverride:
          repository: ghcr.io/open-telemetry/demo
          tag: "2.0.2-flagd-ui"
        useDefault:
          env: true
        service:
          port: 4000
        env:
          - name: FLAGD_METRICS_EXPORTER
            value: otel
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318
        resources:
          limits:
            memory: 100Mi
        volumeMounts:
          - name: config-rw
            mountPath: /app/data
    initContainers:
      - name: init-config
        image: busybox
        command:
          [
            "sh",
            "-c",
            "cp /config-ro/demo.flagd.json /config-rw/demo.flagd.json && cat /config-rw/demo.flagd.json",
          ]
        volumeMounts:
          - mountPath: /config-ro
            name: config-ro
          - mountPath: /config-rw
            name: config-rw
    additionalVolumes:
      - name: config-ro
        configMap:
          name: flagd-config

  kafka:
    enabled: true
    imageOverride:
      repository: ghcr.io/open-telemetry/demo
      tag: "2.0.2-kafka"
    useDefault:
      env: false
    replicas: 1
    ports:
      - name: plaintext
        value: 9092
      - name: controller
        value: 9093
    env:
      - name: KAFKA_ADVERTISED_LISTENERS
        value: PLAINTEXT://kafka:9092
      - name: KAFKA_HEAP_OPTS
        value: "-Xmx800M -Xms800M"
      - name: KAFKA_OPTS
        value: ""
    resources:
      limits:
        memory: 1Gi
    securityContext:
      runAsUser: 1000 # appuser
      runAsGroup: 1000
      runAsNonRoot: true

  valkey-cart:
    enabled: true
    useDefault:
      env: true
    imageOverride:
      repository: "valkey/valkey"
      tag: "7.2-alpine"
    replicas: 1
    ports:
      - name: valkey-cart
        value: 6379
    resources:
      limits:
        memory: 20Mi
    securityContext:
      runAsUser: 999 # valkey
      runAsGroup: 1000
      runAsNonRoot: true

  jaeger-mcp-server:
    enabled: true
    useDefault:
      env: false
    imageOverride:
      repository: thouqueerahmedml/otel-demo
      tag: "latest-jaeger-mcp"
    service:
      port: 8000
      type: LoadBalancer
    env:
      # Needed for in-house built Jaeger MCP
      - name: JAEGER_API_URL
        value: "http://jaeger-query"
      - name: FASTMCP_EXPERIMENTAL_ENABLE_NEW_OPENAPI_PARSER
        value: "true"
      # Needed for public Jaeger MCP. Just retaining it in case we need to use original Jaeger MCP
      - name: JAEGER_URL
        value: "http://jaeger-query"
      - name: JAEGER_PROTOCOL
        value: "HTTP"
      - name: JAEGER_PORT
        value: "80"
    resources:
      limits:
        memory: 512Mi
      requests:
        memory: 512Mi

  db-connection-exhauster:
    enabled: true
    useDefault:
      env: false
    env:
      - name: DB_HOST
        value: "postgresql"
      - name: DB_NAME
        value: "otel"
      - name: DB_USER
        value: "otelu"
      - name: DB_PASSWORD
        value: "otelp"
      - name: DB_PORT
        value: "5432"
      - name: FLAGD_HOST
        value: flagd
      - name: FLAGD_PORT
        value: "8013"
    resources:
      limits:
        memory: 100Mi
      requests:
        memory: 50Mi
    initContainers:
      - name: wait-for-postgres
        image: postgres:15
        command:
          [
            "sh",
            "-c",
            "until pg_isready -h postgresql -p 5432; do echo 'Waiting for PostgreSQL...'; sleep 2; done;",
          ]

apps-otel-collector:
  enabled: true
  image:
    repository: "otel/opentelemetry-collector-contrib"
  fullnameOverride: otel-collector
  mode: deployment
  presets:
    kubernetesAttributes:
      enabled: true
  resources:
    limits:
      memory: 256Mi
  service:
    type: ClusterIP
  ports:
    metrics:
      enabled: true
  podAnnotations:
    opentelemetry_community_demo: "true"
  config:
    receivers:
      otlp:
        protocols:
          http:
            # Since this collector needs to receive data from the web, enable cors for all origins
            # `allowed_origins` can be refined for your deployment domain
            cors:
              allowed_origins:
                - "http://*"
                - "https://*"
      httpcheck/frontend-proxy:
        targets:
          - endpoint: http://frontend-proxy:8080
      redis:
        endpoint: "valkey-cart:6379"
        collection_interval: 10s
      nginx:
        endpoint: "http://image-provider:8081/status"
        collection_interval: 10s
      postgresql:
        endpoint: "postgresql:5432"
        username: "postgres"
        password: "postgres"
        metrics:
          postgresql.blks_hit:
            enabled: true
          postgresql.blks_read:
            enabled: true
          postgresql.tup_fetched:
            enabled: true
          postgresql.tup_returned:
            enabled: true
          postgresql.tup_inserted:
            enabled: true
          postgresql.tup_updated:
            enabled: true
          postgresql.tup_deleted:
            enabled: true
          postgresql.deadlocks:
            enabled: true
        databases:
          - otel
          - postgres
        tls:
          insecure: true

    exporters:
      debug:
        verbosity: detailed
        sampling_initial: 5
        sampling_thereafter: 200
      ## Create an exporter to Jaeger using the standard `otlp` export format
      otlp:
        endpoint: jaeger-collector:4317
        tls:
          insecure: true
      # Create an exporter to Prometheus (metrics)
      otlphttp/prometheus:
        endpoint: http://prometheus:9090/api/v1/otlp
        tls:
          insecure: true
      otlphttp/loki:
        endpoint: http://loki:3100/otlp
        tls:
          insecure: true

    processors:
      # This processor is used to help limit high cardinality on next.js span names
      # When this PR is merged (and released) we can remove this transform processor
      # https://github.com/vercel/next.js/pull/64852
      transform:
        error_mode: ignore
        trace_statements:
          - context: span
            statements:
              # could be removed when https://github.com/vercel/next.js/pull/64852 is fixed upstream
              - replace_pattern(name, "\\?.*", "")
              - replace_match(name, "GET /api/products/*", "GET /api/products/{productId}")
      resource:
        attributes:
          - key: service.instance.id
            from_attribute: k8s.pod.uid
            action: insert

    connectors:
      spanmetrics: {}

    service:
      pipelines:
        traces:
          processors:
            - memory_limiter
            - resource
            - transform
            - batch
          exporters:
            - otlp
            - spanmetrics
        metrics:
          receivers:
            - httpcheck/frontend-proxy
            - redis
            - nginx
            - postgresql
            - otlp
            - spanmetrics
          processors:
            - memory_limiter
            - resource
            - batch
          exporters:
            - otlphttp/prometheus
        logs:
          processors:
            - memory_limiter
            - resource
            - batch
          exporters:
            - otlphttp/loki

k8s-cluster-otel-collector:
  enabled: true
  image:
    repository: "ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-k8s"
  command:
    name: "otelcol-k8s"
  fullnameOverride: k8s-cluster-otel-collector
  mode: deployment
  presets:
    kubernetesAttributes:
      enabled: true
    clusterMetrics:
      enabled: true
    kubernetesEvents:
      enabled: true
  resources:
    limits:
      memory: 256Mi
  service:
    type: ClusterIP
  ports:
    metrics:
      enabled: true
  podAnnotations:
    opentelemetry_community_demo: "true"
  config:
    receivers:
      k8s_cluster:
        allocatable_types_to_report:
          - cpu
          - memory
          - ephemeral-storage
          - storage
          - pods
        node_conditions_to_report:
          - Ready
          - MemoryPressure
          - DiskPressure
          - NetworkUnavailable
          - PIDPressure
      otlp:
        protocols:
          http:
            # Since this collector needs to receive data from the web, enable cors for all origins
            # `allowed_origins` can be refined for your deployment domain
            cors:
              allowed_origins:
                - "http://*"
                - "https://*"

    exporters:
      debug:
        verbosity: detailed
        sampling_initial: 5
        sampling_thereafter: 200
      ## Create an exporter to Jaeger using the standard `otlp` export format
      otlp:
        endpoint: jaeger-collector:4317
        tls:
          insecure: true
      # Create an exporter to Prometheus (metrics)
      otlphttp/prometheus:
        endpoint: http://prometheus:9090/api/v1/otlp
        tls:
          insecure: true
      otlphttp/loki:
        endpoint: http://loki:3100/otlp
        tls:
          insecure: true

    connectors:
      spanmetrics: {}

    service:
      pipelines:
        traces:
          processors:
            - memory_limiter
            - batch
          exporters:
            - otlp
            - spanmetrics
        metrics:
          receivers:
            - otlp
            - spanmetrics
          processors:
            - memory_limiter
            - batch
          exporters:
            - otlphttp/prometheus
        logs:
          processors:
            - memory_limiter
            - batch
          exporters:
            - otlphttp/loki

k8s-nodes-otel-collector:
  enabled: true
  image:
    repository: "ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-k8s"
  command:
    name: "otelcol-k8s"
  fullnameOverride: k8s-nodes-otel-collector
  mode: daemonset
  presets:
    kubernetesAttributes:
      enabled: true
    kubeletMetrics:
      enabled: true
    hostMetrics:
      enabled: true
  resources:
    limits:
      memory: 256Mi
  config:
    receivers:
      otlp:
        protocols:
          http:
            # Since this collector needs to receive data from the web, enable cors for all origins
            # `allowed_origins` can be refined for your deployment domain
            cors:
              allowed_origins:
                - "http://*"
                - "https://*"

    exporters:
      debug:
        verbosity: detailed
        sampling_initial: 5
        sampling_thereafter: 200
      ## Create an exporter to Jaeger using the standard `otlp` export format
      otlp:
        endpoint: jaeger-collector:4317
        tls:
          insecure: true
      # Create an exporter to Prometheus (metrics)
      otlphttp/prometheus:
        endpoint: http://prometheus:9090/api/v1/otlp
        tls:
          insecure: true
      otlphttp/loki:
        endpoint: http://loki:3100/otlp
        tls:
          insecure: true

    connectors:
      spanmetrics: {}

    service:
      pipelines:
        traces:
          processors:
            - memory_limiter
            - batch
          exporters:
            - otlp
        metrics:
          receivers:
            - otlp
          processors:
            - memory_limiter
            - batch
          exporters:
            - otlphttp/prometheus
        logs:
          processors:
            - memory_limiter
            - batch
          exporters:
            - otlphttp/loki

jaeger:
  enabled: true
  fullnameOverride: jaeger
  allInOne:
    enabled: false
  provisionDataStore:
    elasticsearch: true
    cassandra: false
  storage:
    type: elasticsearch
  agent:
    enabled: false
  collector:
    enabled: true
    service:
      otlp:
        grpc:
          name: otlp-grpc
          port: 4317
        http:
          name: otlp-http
          port: 4318
    resources:
      limits:
        memory: 1Gi
      requests:
        memory: 512Mi
  query:
    enabled: true
    extraEnv:
      - name: METRICS_STORAGE_TYPE
        value: prometheus
      - name: PROMETHEUS_SERVER_URL
        value: http://prometheus:9090
    service:
      type: LoadBalancer
    resources:
      limits:
        memory: 512Mi
      requests:
        memory: 256Mi
  elasticsearch:
    master:
      resourcesPreset: large
      heapSize: 1536m
      masterOnly: false
      replicaCount: 1
    data:
      replicaCount: 0
    coordinating:
      replicaCount: 0
    ingest:
      replicaCount: 0

kube-state-metrics:
  enabled: true

prometheus:
  enabled: true
  alertmanager:
    enabled: false
  configmapReload:
    prometheus:
      enabled: true
  kube-state-metrics:
    enabled: false
  prometheus-node-exporter:
    enabled: true
  prometheus-pushgateway:
    enabled: false
  server:
    retention: 2h
    fullnameOverride: prometheus
    extraFlags:
      - "enable-feature=exemplar-storage"
      - "web.enable-otlp-receiver"
      - "web.enable-lifecycle"
    persistentVolume:
      enabled: false
    service:
      servicePort: 9090
    resources:
      limits:
        memory: 2Gi
      requests:
        memory: 2Gi
    configPath: /etc/config/minimal-prometheus.yml
  serverFiles:
    minimal-prometheus.yml:
      global:
        evaluation_interval: 30s
        scrape_interval: 5s
        scrape_timeout: 3s
      storage:
        tsdb:
          out_of_order_time_window: 30m
      otlp:
        keep_identifying_resource_attributes: true
        promote_resource_attributes:
          - service.instance.id
          - service.name
          - service.namespace
          - cloud.availability_zone
          - cloud.region
          - container.name
          - deployment.environment.name
          - k8s.cluster.name
          - k8s.container.name
          - k8s.cronjob.name
          - k8s.daemonset.name
          - k8s.deployment.name
          - k8s.job.name
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.replicaset.name
          - k8s.statefulset.name
          - postgresql.database.name
          - postgresql.schema.name
          - postgresql.table.name
          - postgresql.index.name
      rule_files:
        - /etc/config/recording_rules.yml
        - /etc/config/alerting_rules.yml
        - /etc/config/rules
        - /etc/config/alerts
      scrape_configs:
        - job_name: prometheus
          static_configs:
          - targets:
            - localhost:9090
        - job_name: 'kube-state-metrics'
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
          - source_labels: [__meta_kubernetes_service_name]
            regex: '.*kube-state-metrics.*'
            action: keep
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_name
        - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          job_name: kubernetes-apiservers
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
          - action: keep
            regex: default;kubernetes;https
            source_labels:
            - __meta_kubernetes_namespace
            - __meta_kubernetes_service_name
            - __meta_kubernetes_endpoint_port_name
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          job_name: kubernetes-nodes
          kubernetes_sd_configs:
          - role: node
          relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - replacement: kubernetes.default.svc:443
            target_label: __address__
          - regex: (.+)
            replacement: /api/v1/nodes/$1/proxy/metrics
            source_labels:
            - __meta_kubernetes_node_name
            target_label: __metrics_path__
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          job_name: kubernetes-nodes-cadvisor
          kubernetes_sd_configs:
          - role: node
          relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - replacement: kubernetes.default.svc:443
            target_label: __address__
          - regex: (.+)
            replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
            source_labels:
            - __meta_kubernetes_node_name
            target_label: __metrics_path__
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        - honor_labels: true
          job_name: kubernetes-service-endpoints
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scrape
          - action: drop
            regex: true
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: (.+?)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
            - __address__
            - __meta_kubernetes_service_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_service_name
            target_label: service
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_node_name
            target_label: node
        - honor_labels: true
          job_name: kubernetes-service-endpoints-slow
          kubernetes_sd_configs:
          - role: endpoints
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: (.+?)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
            - __address__
            - __meta_kubernetes_service_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_service_name
            target_label: service
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_node_name
            target_label: node
          scrape_interval: 5m
          scrape_timeout: 30s
        - honor_labels: true
          job_name: prometheus-pushgateway
          kubernetes_sd_configs:
          - role: service
          relabel_configs:
          - action: keep
            regex: pushgateway
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_probe
        - honor_labels: true
          job_name: kubernetes-services
          kubernetes_sd_configs:
          - role: service
          metrics_path: /probe
          params:
            module:
            - http_2xx
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_service_annotation_prometheus_io_probe
          - source_labels:
            - __address__
            target_label: __param_target
          - replacement: blackbox
            target_label: __address__
          - source_labels:
            - __param_target
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels:
            - __meta_kubernetes_namespace
            target_label: namespace
          - source_labels:
            - __meta_kubernetes_service_name
            target_label: service
        - honor_labels: true
          job_name: kubernetes-pods
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scrape
          - action: drop
            regex: true
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
            replacement: '[$2]:$1'
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_port
            - __meta_kubernetes_pod_ip
            target_label: __address__
          - action: replace
            regex: (\d+);((([0-9]+?)(\.|$)){4})
            replacement: $2:$1
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_port
            - __meta_kubernetes_pod_ip
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_name
            target_label: pod
          - action: drop
            regex: Pending|Succeeded|Failed|Completed
            source_labels:
            - __meta_kubernetes_pod_phase
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_node_name
            target_label: node
        - honor_labels: true
          job_name: kubernetes-pods-slow
          kubernetes_sd_configs:
          - role: pod
          relabel_configs:
          - action: keep
            regex: true
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
            replacement: '[$2]:$1'
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_port
            - __meta_kubernetes_pod_ip
            target_label: __address__
          - action: replace
            regex: (\d+);((([0-9]+?)(\.|$)){4})
            replacement: $2:$1
            source_labels:
            - __meta_kubernetes_pod_annotation_prometheus_io_port
            - __meta_kubernetes_pod_ip
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_name
            target_label: pod
          - action: drop
            regex: Pending|Succeeded|Failed|Completed
            source_labels:
            - __meta_kubernetes_pod_phase
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_node_name
            target_label: node
          scrape_interval: 5m
          scrape_timeout: 30s

opensearch:
  enabled: false

loki:
  enabled: true
  fullnameOverride: loki
  deploymentMode: SingleBinary
  singleBinary:
    replicas: 1
    resources:
      limits:
        memory: 2Gi
      requests:
        memory: 2Gi
  # Cache configurations for improved performance
  chunksCache:
    enabled: true
    replicas: 1
    allocatedMemory: 512
    resources:
      limits:
        cpu: 250m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 512Mi
  resultsCache:
    enabled: true
    replicas: 1
    allocatedMemory: 512
    resources:
      limits:
        cpu: 200m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 512Mi
  loki:
    commonConfig:
      replication_factor: 1
    schemaConfig:
      configs:
        - from: 2024-04-01
          store: tsdb
          object_store: filesystem
          schema: v13
          index:
            prefix: loki_index_
            period: 24h
    storage:
      type: filesystem
      filesystem:
        chunks_directory: /var/loki/chunks
        rules_directory: /var/loki/rules
    server:
      http_listen_port: 3100
      grpc_listen_port: 9095
    auth_enabled: false
    limits_config:
      retention_period: 24h
  backend:
    replicas: 0
  read:
    replicas: 0
  write:
    replicas: 0
  ingester:
    replicas: 0
  querier:
    replicas: 0
  queryFrontend:
    replicas: 0
  queryScheduler:
    replicas: 0
  distributor:
    replicas: 0
  compactor:
    replicas: 0
  indexGateway:
    replicas: 0
  lokiCanary:
    enabled: false
  test:
    enabled: false

postgresql:
  enabled: true
  fullnameOverride: postgresql
  auth:
    username: otelu
    password: otelp
    database: otel
    postgresPassword: postgres
  primary:
    persistence:
      enabled: false
    initdb:
      scripts:
        init.sql: |
          -- Copyright The OpenTelemetry Authors
          -- SPDX-License-Identifier: Apache-2.0

          CREATE USER otelu WITH PASSWORD 'otelp';

          -- Create a table
          CREATE TABLE "order" (
              order_id TEXT PRIMARY KEY
          );

          CREATE TABLE shipping (
              shipping_tracking_id TEXT PRIMARY KEY,
              shipping_cost_currency_code TEXT NOT NULL,
              shipping_cost_units BIGINT NOT NULL,
              shipping_cost_nanos INT NOT NULL,
              street_address TEXT,
              city TEXT,
              state TEXT,
              country TEXT,
              zip_code TEXT,
              order_id TEXT NOT NULL,
              FOREIGN KEY (order_id) REFERENCES "order"(order_id) ON DELETE CASCADE
          );

          CREATE TABLE orderitem (
              item_cost_currency_code TEXT NOT NULL,
              item_cost_units BIGINT NOT NULL,
              item_cost_nanos INT NOT NULL,
              product_id TEXT NOT NULL,
              quantity INT NOT NULL,
              order_id TEXT NOT NULL,
              PRIMARY KEY (order_id, product_id),
              FOREIGN KEY (order_id) REFERENCES "order"(order_id) ON DELETE CASCADE
          );

          GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO otelu;
  resources:
    limits:
      memory: 256Mi
    requests:
      memory: 128Mi

grafana:
  enabled: true
  fullnameOverride: grafana
  testFramework:
    enabled: false
  grafana.ini:
    auth:
      disable_login_form: true
    auth.anonymous:
      enabled: true
      org_name: Main Org.
      org_role: Admin
    server:
      root_url: "%(protocol)s://%(domain)s:%(http_port)s/grafana"
      serve_from_sub_path: true
  adminPassword: admin
  plugins: []
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          uid: webstore-metrics
          type: prometheus
          url: http://prometheus:9090
          editable: true
          isDefault: true
          jsonData:
            exemplarTraceIdDestinations:
              - datasourceUid: webstore-traces
                name: trace_id
              - url: http://jaeger-query:80/api/traces/$${__value.raw}
                name: trace_id
                urlDisplayLabel: View in Jaeger UI
        - name: Jaeger
          uid: webstore-traces
          type: jaeger
          url: http://jaeger-query:80
          editable: true
          isDefault: false
        - name: Loki
          uid: webstore-logs
          type: loki
          url: http://loki:3100
          access: proxy
          editable: true
          isDefault: false
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: "default"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
  dashboardsConfigMaps:
    default: grafana-dashboards
  resources:
    limits:
      memory: 1Gi
    requests:
      memory: 1Gi
  alerting:
    rules.yaml:
      apiVersion: 1
      groups:
        - orgId: 1
          name: kafka
          folder: Demo-Alerts
          interval: 1m
          rules:
            - uid: ceud261tkb6yoc
              title: KafkaConsumerLagHigh
              condition: C
              data:
                - refId: A
                  relativeTimeRange:
                    from: 300
                    to: 0
                  datasourceUid: webstore-metrics
                  model:
                    adhocFilters: []
                    datasource:
                      type: prometheus
                      uid: webstore-metrics
                    editorMode: code
                    expr: kafka_consumergroup_lag
                    instant: true
                    interval: ""
                    intervalMs: 15000
                    legendFormat: "{{`{{consumergroup}} - {{topic}}-p{{partition}}`}}"
                    maxDataPoints: 43200
                    range: false
                    refId: A
                - refId: C
                  datasourceUid: __expr__
                  model:
                    conditions:
                      - evaluator:
                          params:
                            - 100
                          type: gt
                        operator:
                          type: and
                        query:
                          params:
                            - C
                        reducer:
                          params: []
                          type: last
                        type: query
                    datasource:
                      type: __expr__
                      uid: __expr__
                    expression: A
                    intervalMs: 5000
                    maxDataPoints: 43200
                    refId: C
                    type: threshold
              dashboardUid: kafkaDashboard
              panelId: 23
              noDataState: NoData
              execErrState: Error
              for: 30s
              labels:
                severity: critical
              annotations:
                __dashboardUid__: kafkaDashboard
                __panelId__: "23"
              isPaused: false
        - orgId: 1
          name: frontend
          folder: Demo-Alerts
          interval: 1m
          rules:
            - uid: aeud5pyhdy22of
              title: API-High-Latency
              condition: C
              data:
                - refId: A
                  relativeTimeRange:
                    from: 300
                    to: 0
                  datasourceUid: webstore-metrics
                  model:
                    adhocFilters: []
                    datasource:
                      type: prometheus
                      uid: webstore-metrics
                    expr: histogram_quantile(0.95, sum by(le, span_name) (rate(traces_span_metrics_duration_milliseconds_bucket{service_name="frontend", span_kind="SPAN_KIND_SERVER", span_name!~"GET|POST"}[5m])))
                    instant: true
                    interval: ""
                    intervalMs: 5000
                    legendFormat: p95 Latency
                    maxDataPoints: 43200
                    range: false
                    refId: A
                - refId: C
                  datasourceUid: __expr__
                  model:
                    conditions:
                      - evaluator:
                          params:
                            - 1000
                          type: gt
                        operator:
                          type: and
                        query:
                          params:
                            - C
                        reducer:
                          params: []
                          type: last
                        type: query
                    datasource:
                      type: __expr__
                      uid: __expr__
                    expression: A
                    intervalMs: 1000
                    maxDataPoints: 43200
                    refId: C
                    type: threshold
              noDataState: NoData
              execErrState: Error
              for: 30s
              labels:
                severity: critical
              annotations: {}
              isPaused: false
        # TODO: Explore below alert further as it is not as expected. We should ideally catch all APIs for better demo purpose
        - orgId: 1
          name: frontend
          folder: Demo-Alerts
          interval: 1m
          rules:
            - uid: eevju1vmswa9sb
              title: API-Failures
              condition: C
              data:
                - refId: A
                  relativeTimeRange:
                    from: 600
                    to: 0
                  datasourceUid: webstore-metrics
                  model:
                    editorMode: code
                    expr: '(rate(traces_span_metrics_calls_total{service_name="frontend", span_name="grpc.oteldemo.CheckoutService/PlaceOrder", status_code="STATUS_CODE_ERROR"}[5m]) / rate(traces_span_metrics_calls_total{service_name="frontend", span_name="grpc.oteldemo.CheckoutService/PlaceOrder"}[5m])) * 100 '
                    instant: true
                    intervalMs: 1000
                    legendFormat: __auto
                    maxDataPoints: 43200
                    range: false
                    refId: A
                - refId: C
                  datasourceUid: __expr__
                  model:
                    conditions:
                        - evaluator:
                            params:
                                - 50
                            type: gt
                          operator:
                            type: and
                          query:
                            params:
                                - C
                          reducer:
                            params: []
                            type: last
                          type: query
                    datasource:
                        type: __expr__
                        uid: __expr__
                    expression: A
                    intervalMs: 1000
                    maxDataPoints: 43200
                    refId: C
                    type: threshold
              noDataState: NoData
              execErrState: Error
              for: 1m
              isPaused: false
              notification_settings:
                receiver: grafana-default-email

grafana-mcp-server:
  fullnameOverride: grafana-mcp-server
  disabledCategories:
    - admin
    - incident
    - alerting
    - oncall
    - sift
    - pyroscope
    - asserts
    - navigation
  image:
    pullPolicy: Always
    repository: thouqueerahmedml/otel-demo
    tag: mcp-grafana-0.6.2
  grafana:
    url: "http://grafana:80"
    apiKey: "na"
  resources:
    limits:
      memory: 512Mi
    requests:
      memory: 512Mi
  service:
    port: 8000
    type: LoadBalancer
