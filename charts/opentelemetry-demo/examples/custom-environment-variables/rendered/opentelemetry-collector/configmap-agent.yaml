---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/configmap-agent.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-agent
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.142.2
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: example
    app.kubernetes.io/version: "0.142.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: opentelemetry-collector
    app.kubernetes.io/component: agent-collector
data:
  relay: |
    connectors:
      spanmetrics: {}
    exporters:
      debug: {}
      opensearch:
        http:
          endpoint: http://opensearch:9200
          tls:
            insecure: true
        logs_index: otel-logs
        logs_index_time_format: yyyy-MM-dd
      otlp/jaeger:
        endpoint: jaeger:4317
        sending_queue:
          batch: null
        tls:
          insecure: true
      otlphttp/prometheus:
        endpoint: http://prometheus:9090/api/v1/otlp
        sending_queue:
          batch: null
        tls:
          insecure: true
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      k8s_leader_elector/k8s_cluster:
        auth_type: serviceAccount
        lease_name: k8s.cluster.receiver.opentelemetry.io
        lease_namespace: default
      k8s_observer:
        auth_type: serviceAccount
        node: ${env:K8S_NODE_NAME}
    processors:
      attributes:
        actions:
        - action: insert
          key: app.eng.team
          value: ring
        include:
          match_type: strict
          services:
          - frontend-proxy
      batch: {}
      k8sattributes:
        extract:
          metadata:
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.node.name
          - k8s.pod.start_time
          - k8s.deployment.name
          - k8s.replicaset.name
          - k8s.replicaset.uid
          - k8s.daemonset.name
          - k8s.daemonset.uid
          - k8s.job.name
          - k8s.job.uid
          - k8s.container.name
          - k8s.cronjob.name
          - k8s.statefulset.name
          - k8s.statefulset.uid
          - container.image.tag
          - container.image.name
          - k8s.cluster.uid
          - service.namespace
          - service.name
          - service.version
          - service.instance.id
          otel_annotations: true
        filter:
          node_from_env_var: K8S_NODE_NAME
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: connection
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      resource:
        attributes:
        - action: insert
          from_attribute: k8s.pod.uid
          key: service.instance.id
      resourcedetection:
        detectors:
        - env
        - system
      transform:
        error_mode: ignore
        trace_statements:
        - context: span
          statements:
          - set(span.attributes["http.route"], "/api/cart") where span.kind == SPAN_KIND_SERVER
            and resource.attributes["service.name"] == "frontend" and span.attributes["http.route"]
            == nil and IsMatch(span.attributes["http.target"], "\\/api\\/cart")
          - set(span.attributes["http.route"], "/api/checkout") where span.kind == SPAN_KIND_SERVER
            and resource.attributes["service.name"] == "frontend" and span.attributes["http.route"]
            == nil and IsMatch(span.attributes["http.target"], "\\/api\\/checkout")
          - set(span.attributes["http.route"], "/api/products/{productId}") where span.kind
            == SPAN_KIND_SERVER and resource.attributes["service.name"] == "frontend"
            and span.attributes["http.route"] == nil and IsMatch(span.attributes["http.target"],
            "\\/api\\/products\\/.*")
          - set(span.attributes["http.route"], "/api/recommendations") where span.kind
            == SPAN_KIND_SERVER and resource.attributes["service.name"] == "frontend"
            and span.attributes["http.route"] == nil and IsMatch(span.attributes["http.target"],
            "\\/api\\/recommendations")
          - set(span.attributes["http.route"], "/api/data") where span.kind == SPAN_KIND_SERVER
            and resource.attributes["service.name"] == "frontend" and span.attributes["http.route"]
            == nil and IsMatch(span.attributes["http.target"], "\\/api\\/data.*")
          - set_semconv_span_name("1.37.0", "original_span_name")
    receivers:
      hostmetrics:
        collection_interval: 10s
        root_path: /hostfs
        scrapers:
          cpu: null
          disk: null
          filesystem:
            exclude_fs_types:
              fs_types:
              - autofs
              - binfmt_misc
              - bpf
              - cgroup2
              - configfs
              - debugfs
              - devpts
              - devtmpfs
              - fusectl
              - hugetlbfs
              - iso9660
              - mqueue
              - nsfs
              - overlay
              - proc
              - procfs
              - pstore
              - rpc_pipefs
              - securityfs
              - selinuxfs
              - squashfs
              - sysfs
              - tracefs
              match_type: strict
            exclude_mount_points:
              match_type: regexp
              mount_points:
              - /dev/*
              - /proc/*
              - /sys/*
              - /run/k3s/containerd/*
              - /var/lib/docker/*
              - /var/lib/kubelet/*
              - /snap/*
          load: null
          memory: null
          network: null
      jaeger:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:14250
          thrift_compact:
            endpoint: ${env:MY_POD_IP}:6831
          thrift_http:
            endpoint: ${env:MY_POD_IP}:14268
      k8s_cluster:
        collection_interval: 10s
        k8s_leader_elector: k8s_leader_elector/k8s_cluster
      kubeletstats:
        auth_type: serviceAccount
        collection_interval: 20s
        endpoint: ${env:K8S_NODE_IP}:10250
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            cors:
              allowed_origins:
              - http://*
              - https://*
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
      receiver_creator/metrics:
        discovery:
          enabled: true
        watch_observers:
        - k8s_observer
      zipkin:
        endpoint: ${env:MY_POD_IP}:9411
    service:
      extensions:
      - health_check
      - k8s_observer
      - k8s_leader_elector/k8s_cluster
      pipelines:
        logs:
          exporters:
          - opensearch
          - debug
          processors:
          - k8sattributes
          - memory_limiter
          - resourcedetection
          - resource
          - batch
          receivers:
          - otlp
        metrics:
          exporters:
          - otlphttp/prometheus
          - debug
          processors:
          - k8sattributes
          - memory_limiter
          - resourcedetection
          - resource
          - batch
          receivers:
          - otlp
          - spanmetrics
          - receiver_creator/metrics
          - hostmetrics
          - kubeletstats
          - k8s_cluster
        traces:
          exporters:
          - otlp/jaeger
          - debug
          - spanmetrics
          processors:
          - k8sattributes
          - memory_limiter
          - attributes
          - spanmetrics
          - batch
          receivers:
          - otlp
          - jaeger
          - zipkin
      telemetry:
        metrics:
          level: detailed
          readers:
          - periodic:
              exporter:
                otlp:
                  endpoint: http://otel-collector:4318
                  insecure: true
                  protocol: http/protobuf
              interval: 10000
              timeout: 5000
